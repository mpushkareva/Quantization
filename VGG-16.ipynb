{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T10:28:43.106324Z",
     "start_time": "2020-04-02T10:28:43.103323Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T10:28:43.881501Z",
     "start_time": "2020-04-02T10:28:43.862496Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import scipy as sp\n",
    "from scipy import special\n",
    "from scipy import stats\n",
    "import xlwt\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy import integrate\n",
    "\n",
    "\n",
    "def f(x, func, kde, X, x_min, x_max):\n",
    "    y, px, cov, p = func(x, kde, X, x_min, x_max)\n",
    "    return cov\n",
    "\n",
    "def grad(x, func, kde, X, x_min, x_max, alpha=10):\n",
    "    y, px, cov, p = func(x, kde, X, x_min, x_max)\n",
    "    step = alpha * px  * (y[1:] - y[:-1]) * (y[1:] + y[:-1] - 2 * x) / 2\n",
    "    return step\n",
    "\n",
    "def cov_kde(x0, kde, X, x_min, x_max):\n",
    "    p = np.zeros(len(x0) + 1)\n",
    "    C = np.zeros(len(x0) + 1) \n",
    "    y = np.zeros(len(x0) + 1) \n",
    "    x_ext = sorted(np.append(x0, [x_min, x_max]))\n",
    "    for i in range(len(x_ext)-1):\n",
    "        mask = np.logical_and(x_ext[i] < X, X <= x_ext[i + 1])\n",
    "        p[i] = len(X[mask]) \n",
    "        C[i] = np.sum(X[mask]) \n",
    "        if p[i] == 0: \n",
    "            C[i] = 0\n",
    "            p[i] = 1\n",
    "    y = C / p\n",
    "    px = kde.evaluate(x0)\n",
    "    cov = np.linalg.norm(C / np.sqrt(p)) #/ sigma_kde\n",
    "    return y, px, cov, p\n",
    "\n",
    "def exponential_discretisation(X, bits):\n",
    "    std_W = np.std(X)\n",
    "    max_W = np.fabs(X).max()\n",
    "    x0 = (std_W / max_W) * 0.5**(bits-1)\n",
    "    signs = np.sign(X)\n",
    "    q_a = np.fabs(X.flatten()) / max_W\n",
    "    n = 2 ** (bits - 1)\n",
    "    q = 1 / x0 ** (1 / (n - 1))\n",
    "    assert (x0 < 1)\n",
    "    xx = [0] + [x0 * q ** i for i in range(n)]\n",
    "    q_mean = np.zeros(q_a.size, dtype=np.float) + np.mean(q_a[q_a > xx[n - 1]])\n",
    "    for i in range(len(xx) - 2):\n",
    "        ii = np.logical_and(xx[i] < q_a, q_a <= xx[i + 1])\n",
    "        q_mean[ii] = np.mean(q_a[ii])\n",
    "    new_W = np.reshape(q_mean, X.shape) * signs * max_W\n",
    "    return new_W, np.corrcoef(np.ravel(X), np.ravel(new_W))[1,0], np.array(xx) * max_W\n",
    "\n",
    "def linear_discretization_ceil_nonzero(X, bitwidth):\n",
    "    std_W = np.std(X)\n",
    "    max_W = np.fabs(X).max()\n",
    "    x0 = (std_W / max_W) * 0.5**(bitwidth-1)\n",
    "    M = np.fabs(X).max()\n",
    "    signs = np.sign(X)\n",
    "    assert(x0 < 1)\n",
    "    n = 2 ** (bitwidth - 1)# the number of gradation\n",
    "    q = (1 - x0) / (n - 1)\n",
    "    q_weights = np.fabs(X.flatten()) / M # between 0 and 1\n",
    "    q_weights[abs(q_weights - 1.0) < 1e-7] = 1.0 - 1e-7 # remove maximal\n",
    "    q_int = np.zeros(q_weights.size, dtype=np.int)\n",
    "    q_int[q_weights <= x0] = 0\n",
    "    q_int[q_weights > x0] = np.ceil((q_weights[q_weights > x0] - x0) / q)  # integers  \n",
    "    x = x0 + q * q_int\n",
    "    x = np.array(x, dtype=np.float16)\n",
    "    xx = [0] + [x0 + q * i for i in range(n)]\n",
    "    new_W = np.reshape(x, X.shape) * signs * M\n",
    "    return new_W, np.corrcoef(np.ravel(X), np.ravel(new_W))[1,0], np.array(xx) * max_W\n",
    "\n",
    "def results(kde, w, x0, x_min, x_max, func, bits, alpha=1, tol_curr=1e-4, ans_case='CG'):\n",
    "    \n",
    "    n_d = 2 ** bits\n",
    "    \n",
    "    fx = lambda x: -f(x, func, kde, w, x_min, x_max)\n",
    "    gradx = lambda x: -grad(x, func, kde, w, x_min, x_max, alpha)\n",
    "    \n",
    "    ans = minimize(fun=fx, x0=x0, jac=gradx, method='CG', tol=tol_curr)#, options={'gtol': 1e-1})\n",
    "    solutions = ans['x']\n",
    "    correlations = -ans['fun'] #/ np.std(X_small)\n",
    "    gradients = np.linalg.norm(gradx(ans['x'])) / alpha / n_d\n",
    "    return solutions, correlations, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T10:28:45.063766Z",
     "start_time": "2020-04-02T10:28:45.058765Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_corrs_to_xls(name, results, len_layers, grad_bit, init_discr, alpha=1):\n",
    "    \n",
    "    book = xlwt.Workbook(encoding=\"utf-8\")\n",
    "    sheet1 = book.add_sheet(str(grad_bit) + str(init_discr)) \n",
    "    sheet1.write(0, 0, 'layer')\n",
    "    sheet1.write(0, 1, 'before opt')\n",
    "    sheet1.write(0, 2, 'after opt')\n",
    "    for j in range(len_layers):\n",
    "        sheet1.write(j + 1, 0, results[j, 0])\n",
    "        sheet1.write(j + 1, 1, results[j, 1])\n",
    "        sheet1.write(j + 1, 2, results[j, 2])\n",
    "    book.save('VGG-16' + name + str(grad_bit) + str(init_discr) + '.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T10:28:46.082997Z",
     "start_time": "2020-04-02T10:28:46.078995Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_tops_to_xls(name, top1, top5, grad_bit, init_discr='1', alpha=1):\n",
    "    \n",
    "    book = xlwt.Workbook(encoding=\"utf-8\")\n",
    "    sheet1 = book.add_sheet(init_discr) \n",
    "    sheet1.write(0, 0, 'grad_bit')\n",
    "    sheet1.write(0, 1, 'top1')\n",
    "    sheet1.write(0, 2, 'top5') \n",
    "    sheet1.write(grad_bit-2, 0, grad_bit)\n",
    "    sheet1.write(grad_bit-2, 1, top1)\n",
    "    sheet1.write(grad_bit-2, 2, top5)\n",
    "    book.save(name + 'tops' + str(grad_bit) + str(init_discr) + '.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T10:28:49.533782Z",
     "start_time": "2020-04-02T10:28:49.524779Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_batch_of_images(batch_size = 1000, images_folder='imagenet/preprocessed images val', xml_folder='imagenet/xml val'):  \n",
    "    jpeg_files = [file for file in os.listdir(images_folder)]\n",
    "    random.shuffle(jpeg_files)\n",
    "    jpeg_files_batch = jpeg_files[:batch_size]\n",
    "    batch = []\n",
    "    for i in range(batch_size):\n",
    "        img = image.load_img(os.path.join('.', images_folder, jpeg_files_batch[i]), target_size=(224, 224))\n",
    "        img = image.img_to_array(img)\n",
    "        batch.append(img)\n",
    "\n",
    "    batch = np.asarray(batch)\n",
    "    #x = np.expand_dims(batch, axis=0)\n",
    "    batch = preprocess_input(batch, mode='caffe')\n",
    "    xml_files = [file.split('.')[0] + '.xml' for file in jpeg_files_batch]\n",
    "    answers = []\n",
    "    for i in range(batch_size):\n",
    "        tree = ET.parse(os.path.join(xml_folder, xml_files[i]))\n",
    "        root = tree.getroot()\n",
    "        valid_value = root[5][0].text\n",
    "        answers.append(valid_value)\n",
    "    \n",
    "    return batch, answers\n",
    "\n",
    "def compute_accuracy_on_batch_of_images(batch, model, answers):  \n",
    "    preds = model.predict(batch)\n",
    "    # convert the probabilities to class labels\n",
    "    labels = decode_predictions(preds)\n",
    "    top1_correct = 0\n",
    "    top5_correct = 0\n",
    "    for i in range(len(batch)):\n",
    "        if answers[i] == labels[i][0][0]:\n",
    "            top1_correct += 1\n",
    "        for k in range(5):\n",
    "            if answers[i] in labels[i][k][0]:\n",
    "                top5_correct += 1\n",
    "                break\n",
    "    top1_correct /= len(batch)\n",
    "    top5_correct /= len(batch)\n",
    "    #print(\"Top1:\", top1_correct)\n",
    "    #print(\"Top5:\", top5_correct)\n",
    "    \n",
    "    return top1_correct, top5_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T10:28:51.197156Z",
     "start_time": "2020-04-02T10:28:51.187154Z"
    }
   },
   "outputs": [],
   "source": [
    "def change_all_weights(weights, grad_bit, layers_to_quant, \n",
    "                       init_discr='linear', type_of_change='best', alpha=1):\n",
    "    quant_weights = weights.copy()\n",
    "    layer_correlations = np.zeros((len(layers_to_quant), 3))\n",
    "    row = 0\n",
    "    for layer in layers_to_quant:\n",
    "        layer_correlations[row, 0] = layer\n",
    "        w_rav = np.ravel(quant_weights[layer])\n",
    "        w_norm = (w_rav - np.mean(w_rav)) / np.std(w_rav)\n",
    "        if len(w_norm) > 10000:\n",
    "            w_small = np.random.choice(w_norm, 10000, replace=False)\n",
    "        else: w_small = w_norm\n",
    "        kde = stats.gaussian_kde(w_small, bw_method='scott')\n",
    "        \n",
    "        if init_discr == 'linear':\n",
    "            weights_layer, corr, xx = linear_discretization_ceil_nonzero(w_norm, grad_bit)\n",
    "        else:\n",
    "            weights_layer, corr, xx = exponential_discretisation(w_norm, grad_bit)\n",
    "            \n",
    "        x0 = np.sort(np.append(xx, -xx[1:]))\n",
    "        #print('layer = ', layer)\n",
    "        #print('exp corr = ', corr )\n",
    "        layer_correlations[row, 1] = corr\n",
    "        w_min = x0.min()\n",
    "        w_max = x0.max()\n",
    "        solutions, correlations, gradients = results(kde, w_norm, x0[1:-1],\n",
    "                                                w_min, w_max, cov_kde, grad_bit, alpha=alpha, ans_case='CG')\n",
    "        quant = np.sort(np.append(solutions, [w_max, w_min])) \n",
    "        w_discr = w_rav.copy()\n",
    "        x_discr = cov_kde(solutions, kde, w_norm, w_min, w_max)[0]\n",
    "        for i in range(len(quant) - 1):\n",
    "            mask = np.logical_and(quant[i] <= w_norm, quant[i+1] >= w_norm)\n",
    "            w_discr[mask] = x_discr[i] * np.std(w_rav) + np.mean(w_rav)\n",
    "        \n",
    "        layer_correlations[row, 2] = np.corrcoef(w_rav, w_discr)[1,0]\n",
    "        \n",
    "        if type_of_change =='best' and np.corrcoef(w_rav, w_discr)[1,0] < corr:\n",
    "            quant_weights[layer] = weights_layer.reshape(quant_weights[layer].shape) *\\\n",
    "                                        np.std(w_rav) + np.mean(w_rav)\n",
    "        else:\n",
    "            quant_weights[layer] = w_discr.reshape(quant_weights[layer].shape)\n",
    "            \n",
    "        row += 1\n",
    "    save_corrs_to_xls(type_of_change, layer_correlations, len(layers_to_quant), grad_bit, init_discr, alpha)\n",
    "    return quant_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T10:29:01.547137Z",
     "start_time": "2020-04-02T10:28:55.067028Z"
    }
   },
   "outputs": [],
   "source": [
    "batch, true_answers = load_batch_of_images(batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T17:39:13.315639Z",
     "start_time": "2020-04-02T10:29:01.547137Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "bit_list = [3, 4, 5, 6, 7]\n",
    "\n",
    "model = VGG16(weights='imagenet')\n",
    "weights = np.array(model.get_weights())\n",
    "\n",
    "layers_to_quant = []\n",
    "for i in range(len(weights)):\n",
    "    if weights[i].ndim != 1:\n",
    "        layers_to_quant.append(i)\n",
    "        \n",
    "for B in bit_list:\n",
    "    \n",
    "    q_weights = weights.copy()\n",
    "    \n",
    "    #exponential\n",
    "    \n",
    "    for i in layers_to_quant:\n",
    "        q_weights[i] = exponential_discretisation(q_weights[i], B)[0]\n",
    "    \n",
    "    model.set_weights(q_weights)\n",
    "    top1, top5 = compute_accuracy_on_batch_of_images(batch, model, true_answers)\n",
    "    save_tops_to_xls('VGG-16' + ' exponential', top1, top5, B)\n",
    "    #linear with optimal x0\n",
    "    \n",
    "    q_weights = weights.copy()\n",
    "    \n",
    "    for i in layers_to_quant:\n",
    "        q_weights[i] = linear_discretization_ceil_nonzero(q_weights[i], B)[0]\n",
    "    \n",
    "    model.set_weights(q_weights)\n",
    "    top1, top5 = compute_accuracy_on_batch_of_images(batch, model, true_answers)\n",
    "    save_tops_to_xls('VGG-16' + ' linear', top1, top5, B)\n",
    "    \n",
    "    q_weights = weights.copy()\n",
    "    \n",
    "    \n",
    "    q_weights = change_all_weights(weights, B, layers_to_quant, init_discr='exp', type_of_change='best')\n",
    "    model.set_weights(q_weights)\n",
    "    top1, top5 = compute_accuracy_on_batch_of_images(batch, model, true_answers)\n",
    "    save_tops_to_xls('VGG-16 best', top1, top5, B, init_discr='exp')\n",
    "    \n",
    "    q_weights = weights.copy()\n",
    "    \n",
    "    q_weights = change_all_weights(weights, B, layers_to_quant, init_discr='linear', type_of_change='best')\n",
    "    \n",
    "    \n",
    "    model.set_weights(q_weights)\n",
    "    top1, top5 = compute_accuracy_on_batch_of_images(batch, model, true_answers)\n",
    "    save_tops_to_xls('VGG-16 best', top1, top5, B, init_discr='linear')\n",
    "    \n",
    "    \n",
    "    q_weights = weights.copy()\n",
    "    \n",
    "    q_weights = change_all_weights(weights, B, layers_to_quant, init_discr='exp', type_of_change='last')\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.set_weights(q_weights)\n",
    "    top1, top5 = compute_accuracy_on_batch_of_images(batch, model, true_answers)\n",
    "    save_tops_to_xls('VGG-16 last', top1, top5, B, init_discr='exp')\n",
    "    \n",
    "    q_weights = weights.copy()\n",
    "    \n",
    "    q_weights = change_all_weights(weights, B, layers_to_quant, init_discr='linear', type_of_change='last')\n",
    "      \n",
    "    \n",
    "    model.set_weights(q_weights)\n",
    "    top1, top5 = compute_accuracy_on_batch_of_images(batch, model, true_answers)\n",
    "    save_tops_to_xls('VGG-16 last', top1, top5, B, init_discr='linear')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-03T17:44:00.157647Z",
     "start_time": "2020-04-03T17:39:13.315639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.729, 0.905)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet')\n",
    "weights = np.array(model.get_weights())\n",
    "\n",
    "compute_accuracy_on_batch_of_images(batch, model, true_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
